seed: 0

env:
  max_steps: 250
  scenario_name: "custom_scenario"  # Name of the scenario to be used
  scenario:
    n_agents: 4
  device: ??? # These values will be populated dynamically
  vmas_envs: ???

model:
  shared_parameters: True
  centralised_critic: True  # MAPPO if True, IPPO if False
  embedding_size: 1024

collector:
  frames_per_batch: 50_000 # Frames sampled each sampling iteration
  n_iters: 300 # Number of sampling/training iterations
  total_frames: ???

buffer:
  memory_size: ???

loss:
  gamma: 0.99
  lmbda: 0.9
  entropy_eps: 0
  entropy_coef: 0.00
  clip_epsilon: 0.2

train:
  num_epochs: 50  # optimization steps per batch of data collected
  minibatch_size: 5000 # size of minibatches used in each epoch
  lr: 5e-5
  max_grad_norm: 5.0
  checkpoint_interval: 10
  checkpoint_dir: "/Users/nicolaspfitzer/ProrokLab/CustomScenarios/checkpoints/torchrl_mappo"
  device: ???

eval:
  evaluation_interval: 4
  evaluation_episodes: 1

logger:
  backend: csv
  #backend: wandb # Delete to remove logging
  project_name: null
  group_name: null